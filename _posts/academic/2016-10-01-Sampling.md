---
layout: post-no-feature
title: Sampling Methods on the YFCC 100M Dataset
description: "Image tagging and retrieval on large scale unstructured data using sampling methods."
categories: articles
comments: true
date: 2016-10-01
tags: [software]
---


The following is work done at Lab41, though initially started at Lawrence Livermore National Laboratory.

By now, maybe you've heard of the [YFCC 100M Dataset](https://webscope.sandbox.yahoo.com/catalog.php?datatype=i&did=67), and you may even have played around with the dataset. The underlying reasoning for its initial release was its scale: lots of images, lots of metadata. An unexpected issue, though, was its noisiness and overall difficulty in addressing the randomness in the corpus. It's easy to understate this, so there's nothing like actually looking at the data. If you actually parse through the corpus, you'll start to notice individual metadata tags sometimes make sense but oftentimes don't. For example, take the below.

![FlickR Creative Commons from https://www.flickr.com/photos/guenterleitenbauer/17272171332/in/photolist-UbULQ-oJxdAu-4ZhXEf-9UN1Bi-3m4YQy-sjhoMs-73J38d-j1dBZc-5Jv22Z-dYwK6H-Ldqa7-6gc4CL-7cXAsP-5B37Sm-FB9Hp-JbvZxC-pHgXDN-oCUpJ9-7RLduZ-eAW16B-poUzEv-6Q2wNH-bSyyp8-atdXmp-JjGiS4-oTGsxq-515ypv-HUwTYF-8YFaai-gmHyuJ-88pmb5-bECPMC-w4urw-JnPeit-HyNqxQ-hMrztt-f4hgYU-fdvTWF-4TMi9v-HvpJxY-gv1asQ-pRpjEW-HT8SbU-qjLVSo-bqDQCz-8vzYc4-bRrtNT-s6gE7k-7LtUp1-dfDc7T](https://raw.githubusercontent.com/UCKarl/UCKarl.github.io/master/_posts/academic/images/venice.jpg)
```
Metadata Tags: 2015, April, Austria, Canon, Guenter, Günter, Landscape, Leitenbauer, Wels, bild, bilder, canal, canale, city, flickr, foto, fotos, image, images, kanal, key, landschaft, photo, photos, picture, pictures, stadt, town, venedig, venetia, venezia, venice, wasser, water, www.leitenbauer.net, Österreich, burano, island, insel, isola
```

Yes, we'll see `canal, venice, water, architecture`, which perfectly represent the picture. But the other stuff is enough to throw you off. I'm guessing that this was an Austrian Tourist who has a Canon camera, and he went to Venice in April 2015. To get a machine to recognize that is difficult, but that's another story altogether. The YFCC chalenge has been to be able to decipher *content* from an image, and in that sense, the tags `2015, April, Austria, Canon, flickr, foto, fotos, isola` are noise.

That's actually a pretty good example of the tags. There are some that are just inexcusably bad.

![FlickR Creative Commons from https://www.flickr.com/photos/imageborder/11741277024/in/photolist-qTvDJZ-oU4SDj-nVupEh-jEaNgS-nNJP5X-nSg7Cd-oytXam-eob2s2-opNMeb-oxqRfq-og44rm-njrx4M-9VPiN2-o2RKTf-s6uFUq-prHm2P-mvh2GK-omZVbp-huKcCJ-pQZATK-pgFPud-piZaUu-afEMB6-dx3181-ndVey3-zE74Jc-hTGDYX-nEqUsQ-nF4s6X-pfj2yc-o7Ursu-bxbP6B-pizidR-s6oC1x-nSPcU4-paTU56-oCHYpD-hu5wwJ-otgsJy-75fkX2-p1muFT-pdgnp9-8Dq8ZR-iTx7AL-o15sFG-mRseLM-aJuaiM-aD8pKX-owydez-qzaqsZ/](https://raw.githubusercontent.com/UCKarl/UCKarl.github.io/master/_posts/academic/images/waves.png)
```
Metadata Tags: BlinkAgain, my_gear_and_me
```

This is literally the majority of the YFCC dataset; crap like this. It's bad, yes, but the hope is there is enough data to be able to overcome these issues. And, in fact, as you will see, there is...surprisingly so. Again, it's the idea that the individual tag and image will likely not make any sense, but the corpus as a whole will produce a pretty reasonable classifier.

### Word2Vec

One of the more impactful papers in the past few years is Tomas Mikolov's [word2vec](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf). The major takeaway from `word2vec` is their negative sampling approach, through a broader idea of noise contrastive estimation. There are several articles on the description of their cost function on ArXiv and a [previous blog post](https://gab41.lab41.org/anything2vec-e99ec0dc186#.ddnjxweeq), but the idea is that it approximates the binary cross-entropy function through sampling. And it does this by using the *context* of a word to define its meaning, so there's very little supervision. This is especially attractive in our approach (on ArXiv here and submitted to CVPR), because metadata from user generated content (UGC) like the YFCC image and text dataset can be used as the *context of an image*.

#### Negative Sampling

The core of word2vec is the use of sampling. The function as written in his paper is:

$$ \max_{v_i, v_o} \log \sigma( v_o^T v_i ) + \sum_n \mathbb{E}_{n\sim p(i)}\left[ \log \sigma (- v_n^T v_i) \right] $$

Here, $$v_i$$ and $$v_o$$ are the input words and context words, respectively. The first term pulls words together (maximizing correlation) while the second term pushes them away from "negatively sampled" words (what the $$n \sim p(i)$$ denotes). It can be easily shown that if the sum in this term extends to the entire word corpus, the above equation is equivalent to the cross-entropy function. (See [this](https://gab41.lab41.org/anything2vec-e99ec0dc186#.ddnjxweeq) for a visual description.) 

### Extensions to Im2Vec

Lots of people have attempted the im2vec idea with [hierarchical ontologies](https://github.com/li-xirong/hierse) and [semantic transfer](https://arxiv.org/pdf/1604.03249.pdf) and ["fast" zero-shot tagging](https://arxiv.org/pdf/1605.09759.pdf), but no one has seemed to do so at scale on UGC/open source multimedia. By scale, I mean both number of images and number of tags. For reference ImageNet has thousands of labels, YFCC100M has millions. Still, using the simple concept of negative sampling that Mikolov promotes, it's actually not quite difficult of an extension apply to images.

#### Some Equations

Let's say we've extract features $$v_f$$ with CNNs, and we're projecting our features into the same vector space as the context vectors $$v_o$$ with the matrix $$W$$. Then, we can rewrite the word2vec cost function as:

$$ \max_{W} \log \sigma( v_o^T W v_f ) + \sum_n \mathbb{E}_{n \sim p(i)} \left[ \log \sigma(-v_n^T W v_f ) \right] $$

Notice that the only difference between this equation and the word2vec equation is that there is a $$W$$ matrix.

#### The Trouble with GPUs

You might've heard that GPUs are limited in memory. In all actuality, they've gotten pretty beastly in this respect. Also consider that with NVLink, memory sharing could fit tons of data. Still, tags in UGC can number in the tens of millions, especially without constraints on language or spelling errors. Without doing an excessive amount of coding, and if you're a poor researcher with a GeForce 700 series card, you may need an alternative.

Mikolov's work is all done on multi-threaded CPUs, with good reason. The motherboard simply has way more memory. Secondly, he deals with only wide neural networks, which means that optimizing a single layer in parallel may be just fine. It's analogous to HOG-Wild, where you're just randomly optimizing columns. The difference is that the chance of writing over a word vector that's being updated simultaneously is fairly low, since the vocabulary is really large.

I suppose my takeaway here was: use GPUs for deep learning. Use CPUs for wide learning. And maybe that's a good segway into the next section.

#### Sampling Distributions

The beauty of it is, because we are sampling from a distribution, the words `cannon` or `iphoneography`, which apply to a random assortment of images, will only serve to push images away from them during negative sampling. Meanwhile, posive sampling of images, where we sample according to a scaled inverse of the distribution, will pull images toward them of less frequent words.

Recall the word2vec cost function.

$$ \max_{v_i, v_o} \log \sigma( v_o^T v_i ) + \sum_n \mathbb{E}_{n\sim p(i)}\left[ \sigma (- v_n^T v_i) \right] $$

There is that pesky issue of scale. If you've got 600k unique words, your output matrix will be of size 600k, and if you've got a second to last layer at 4096 dimensions, then the dimensionality of that matrix will be $$600k \times 4096$$, a pretty large matrix to backpropagate.

#### Deep and Wide Neural Networks

We want to do sampling based methods

### Code and Repos

Most of this work was done in under six months, but it was enough to get a demo served and up and running. You can access all of the code with the corresponding Docker Containers at the [Lab41 Github Page](http://github.com/lab41/attalos), and if you have any trouble, you can feel free to reach out to [me](mailto:kni@iqt.org).
